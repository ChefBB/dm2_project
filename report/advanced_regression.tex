\section{Advanced Regression}

The chosen target variable is \texttt{averageRating}, which represents 
the average rating (on a 1--10 scale) assigned by IMDb users to each title. The exploratory 
data analysis showed that its distribution is approximately normal, 
with most titles concentrated in the range between 6 and 7. 
%For consistency with the classification task, the dataset was split into training 
%(70\%) and test (30\%) sets using the same stratification strategy.

\subsection{Random Forest Regression}
We applied the \textit{Random Forest Regression} algorithm on the task.
Before training the model, although not strictly necessary for tree-based models, 
we standardized the numerical features for consistency and transformed the categorical feature
\texttt{titleType} using \textit{One-Hot Encoding}.

The hyperparameters were optimized using \textit{RandomizedSearchCV} with 5-fold cross-validation, 
exploring different values for the number of trees (100, \textbf{200}, 300, 400, 500), 
the maximum depth (\textbf{None}, 10, 15, 20, 25, 30), 
the minimum number of samples required for a split (2, \textbf{5}, 10, 15) and for a leaf
(\textbf{1}, 2, 4, 6), and the number of features considered at each split (sqrt, \textbf{log2}). 
The best hyperparameters found are highlighted in bold. 
The \texttt{R\textsuperscript{2}} score was used as the evaluation metric during cross-validation.

 
The optimized Random Forest was first evaluated on the test set (results reported in Table~\ref{tab:rf_metrics}).
Subsequently, the model was retrained using only the 18 most important features identified through feature importance analysis.
Feature selection was guided by a cumulative importance plot, which showed that these 18 features accounted for over 90\% 
of the total importance, effectively reducing the dimensionality from the original 28 features without a significant loss in predictive performance.

\begin{table}[h]
\centering
\caption{Performance of the Random Forest Regressor on the test set 
(full model vs reduced features).}
\label{tab:rf_metrics}
\begin{tabular}{lccc}
\hline
\textbf{Model} & \textbf{MAE} & \textbf{MSE} & \textbf{R\textsuperscript{2}} \\
\hline
Random Forest (All Features) & 0.7536 & 1.0833 & 0.4033 \\
Random Forest (Top 18 Features) & 0.7550 & 1.0922 & 0.3984 \\
\hline
\end{tabular}
\end{table}

The results, reported in Table~\ref{tab:rf_metrics}, indicate that the Random Forest model achieves 
a mean absolute error below one point on the IMDb scale and explains around 40\% of the variance in the target variable. 
Notably, the model trained on only the top 18 features performs almost identically to the full-feature model 
(R\textsuperscript{2}: 0.3984 vs 0.4033), showing that 
predictive power is concentrated in a limited subset of variables. 
%These results represent solid performance, especially considering the subjective nature of ratings and the complexity of the domain.

Feature importance analysis further highlighted that the most influential predictors include both numerical variables,
such as \texttt{runtimeMinutes}, \texttt{startYear}, \texttt{ratingCount}, and \texttt{deltacredits},
and categorical variables derived from the encoding step, such as \texttt{titleType\_tvEpisode}, among others. 

\begin{figure}[h]
\centering
\includegraphics[width=0.7\textwidth]{plotsss/rf_top18_actual_vs_predicted.png} 
\caption{Actual vs Predicted \texttt{averageRating} for the Random Forest model trained on the top 18 features.}
\label{fig:rf_top18_actual_vs_predicted}
\end{figure}


The scatter plot in Figure~\ref{fig:rf_top18_actual_vs_predicted} shows that the predicted ratings roughly follow the trend of 
the actual ratings. Most predictions fall in the 6–7 range, consistent with the distribution of the target variable. 
While the model captures the general pattern, deviations occur, particularly at the extremes, which is consistent with the moderate R² of around 0.40. 
This indicates that the model explains a substantial portion of the variance, but there remains considerable unexplained variability.

% Questione cross validation ???

\subsection{Neural Network Regression}
A feedforward neural network was also implemented for the regression task.

The network has four separate input branches:
\begin{itemize}
    \item \texttt{region}, handled with a 16-neurons Dense layer;
    \item \texttt{genre}, handled with an 8-neurons Dense layer;
    \item \texttt{titleType}, handled with an Embedding layer
    with output dimension of 8, followed by a Flatten layer;
    \item Other numerical features, handled with a 96-neurons
    Dense layer.
\end{itemize}
All numerical features were standardized.
The outputs of these branches were concatenated and passed through
four fully connected layers with 128 neurons each. All layers use
Sigmoid Linear Unit (SiLU) activation functions, Batch Normalization,
and Dropout with a rate of 0.3 for regularization.
The final output layer is a single neuron with a linear activation
function, followed by a Lambda layer to clip the output between 1 and
10.

The model was compiled using the Adam optimizer with a learning rate
of 0.0008 and Mean Squared Error (MSE) as the loss function.
Early stopping was employed to prevent overfitting, monitoring the
validation loss with a patience of 20 epochs.

Figures~\ref{fig:mae_mse_nn} show the training and validation MAE
and MSE over epochs.
Both metrics indicate most of the improvement occurs within
the first few epochs. After that, both slowly keep
decreasing, with very little fluctuations.
The model does not show signs of overfitting.
\begin{figure}[H]
    \centering
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{plotsss/mae_nn.png}
        % \caption{MAE}
        \label{fig:mae_nn}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{plotsss/mse_nn.png}
        % \caption{MSE}
        \label{fig:mse_nn}
    \end{subfigure}
    \caption{Training and validation MAE and MSE over epochs.}
    \label{fig:mae_mse_nn}
\end{figure}

Table~\ref{tab:nn_metrics} summarizes the performance of the
neural network on the test set,
while figure~\ref{fig:nn_actual_vs_predicted} shows the scatter
plot of actual vs predicted ratings.
While Mean Absolute Error (MAE) and Mean Squared Error (MSE) achieve
relatively satisfactory results, the R\textsuperscript{2} score of
0.3667 is a bit underwhelming. This can be explained by the fact
that the vast majority (88.5\%) of predictions fall within the
[5, 9] range. With respect to the Random Forest model's prediction,
shown in figure~\ref{fig:rf_top18_actual_vs_predicted},
the neural network's predictions seem to be a bit more dispersed
in this range.

\begin{figure}[H]
    \centering
    \begin{minipage}{0.4\textwidth}
        \centering
        \begin{tabular}{lcc}
            \hline
            \textbf{MAE} & \textbf{MSE} & \textbf{R\textsuperscript{2}} \\
            \hline
            0.7835 & 1.1518 & 0.3667 \\
            \hline
        \end{tabular}
        \captionof{table}{Performance of the Neural Network Regressor.}
        \label{tab:nn_metrics}
    \end{minipage}
    \hfill
    \begin{minipage}{0.55\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{plotsss/preds_reg_nn.png}
        \caption{Actual vs Predicted \texttt{averageRating} for the Neural Network model.}
        \label{fig:nn_actual_vs_predicted}
    \end{minipage}
\end{figure}