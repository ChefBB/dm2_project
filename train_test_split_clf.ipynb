{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imdb_2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# Path to the original dataset\n",
    "file_path = '/Users/chiaraferrara/Desktop/Unipi/Magistrale/DM 2/dm2_project/dm2_dataset_2425_imdb/imdb_2.csv'\n",
    "\n",
    "# Load the dataset into a pandas DataFrame\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['startYear', 'runtimeMinutes', 'totalCredits', 'canHaveEpisodes',\n",
       "       'numRegions', 'ratingCount', 'castNumber', 'companiesNumber',\n",
       "       'averageRating', 'writerCredits', 'directorsCredits',\n",
       "       'totalNominations', 'totalMedia', 'totalReviews', 'Asia', 'Africa',\n",
       "       'Europe', 'North America', 'South America', 'Australia',\n",
       "       'Continent Unknown', 'genre1', 'genre2', 'genre3', 'movie', 'short',\n",
       "       'tvEpisode', 'tvMiniSeries', 'tvMovie', 'tvSeries', 'tvShort',\n",
       "       'tvSpecial', 'video', 'videoGame'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delta credits = totalCredits - (castNumber + writerCredits + directorsCredits)\n",
    "df['deltaCredits'] = df['totalCredits'] - (df['castNumber'] + df['writerCredits'] + df['directorsCredits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns that are not needed\n",
    "columns_to_drop = [\n",
    "    'totalCredits', 'castNumber', 'writerCredits', 'directorsCredits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['startYear', 'runtimeMinutes', 'canHaveEpisodes', 'numRegions',\n",
       "       'ratingCount', 'companiesNumber', 'averageRating', 'totalNominations',\n",
       "       'totalMedia', 'totalReviews', 'Asia', 'Africa', 'Europe',\n",
       "       'North America', 'South America', 'Australia', 'Continent Unknown',\n",
       "       'genre1', 'genre2', 'genre3', 'movie', 'short', 'tvEpisode',\n",
       "       'tvMiniSeries', 'tvMovie', 'tvSeries', 'tvShort', 'tvSpecial', 'video',\n",
       "       'videoGame', 'deltaCredits'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_cols = ['movie', 'short', 'tvEpisode', 'tvMiniSeries', 'tvMovie', \n",
    "               'tvSeries', 'tvShort', 'tvSpecial', 'video', 'videoGame']\n",
    "\n",
    "# Trova per ogni riga la colonna con valore 1 (cioè la categoria)\n",
    "df['titleType'] = df[onehot_cols].idxmax(axis=1)\n",
    "\n",
    "df = df.drop(columns=onehot_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a stratified 70/30 split based on the 'titleType' column\n",
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.3,\n",
    "    stratify=df['titleType'],\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set saved to: /Users/chiaraferrara/Desktop/Unipi/Magistrale/DM 2/dm2_project/dm2_dataset_2425_imdb/train70_clf.csv\n",
      "Test set saved to: /Users/chiaraferrara/Desktop/Unipi/Magistrale/DM 2/dm2_project/dm2_dataset_2425_imdb/test30_clf.csv\n"
     ]
    }
   ],
   "source": [
    "# Determine the output directory (same as input file)\n",
    "output_dir = os.path.dirname(file_path)\n",
    "\n",
    "# Define output file paths\n",
    "train_path = os.path.join(output_dir, 'train70_clf.csv')\n",
    "test_path = os.path.join(output_dir, 'test30_clf.csv')\n",
    "\n",
    "# Save the train and test splits as CSV files\n",
    "train_df.to_csv(train_path, index=False)\n",
    "test_df.to_csv(test_path, index=False)\n",
    "\n",
    "# Confirm save paths\n",
    "print(f\"Train set saved to: {train_path}\")\n",
    "print(f\"Test set saved to: {test_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessed_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# Path to the original dataset\n",
    "file_path = '/Users/chiaraferrara/Desktop/Unipi/Magistrale/DM 2/dm2_project/dm2_dataset_2425_imdb/preprocessed_full.csv'\n",
    "\n",
    "# Load the dataset into a pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['originalTitle', 'rating', 'startYear', 'endYear', 'runtimeMinutes',\n",
       "       'awardWins', 'numVotes', 'worstRating', 'bestRating', 'totalImages',\n",
       "       'totalVideos', 'totalCredits', 'criticReviewsTotal', 'titleType',\n",
       "       'awardNominationsExcludeWins', 'canHaveEpisodes', 'isRatable',\n",
       "       'isAdult', 'numRegions', 'userReviewsTotal', 'ratingCount',\n",
       "       'countryOfOrigin', 'genres', 'castNumber', 'companiesNumber',\n",
       "       'averageRating', 'regions', 'externalLinks', 'writerCredits',\n",
       "       'directorsCredits', 'soundMixes', 'quotesTotal', 'totalMedia',\n",
       "       'totalNominations', 'deltaCredits', 'regions_freq_enc', 'regions_EU',\n",
       "       'regions_NA', 'regions_AS', 'regions_AF', 'regions_OC', 'regions_SA',\n",
       "       'regions_UNK', 'countryOfOrigin_freq_enc', 'countryOfOrigin_NA',\n",
       "       'countryOfOrigin_AF', 'countryOfOrigin_AS', 'countryOfOrigin_EU',\n",
       "       'countryOfOrigin_OC', 'countryOfOrigin_SA', 'countryOfOrigin_UNK',\n",
       "       'reviewsTotal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total media = sum of images, videos, quotes, and external links\n",
    "df['totalMedia'] = df[['totalImages', 'totalVideos', 'quotesTotal', 'externalLinks']].sum(axis=1)\n",
    "\n",
    "# Delta credits = totalCredits - (castNumber + writerCredits + directorsCredits)\n",
    "df['deltaCredits'] = df['totalCredits'] - (df['castNumber'] + df['writerCredits'] + df['directorsCredits'])\n",
    "\n",
    "# Total nominations = awardWins + awardNominationsExcludeWins\n",
    "df['totalNominations'] = df['awardWins'] + df['awardNominationsExcludeWins']\n",
    "\n",
    "# Total reviews = userReviewsTotal + criticReviewsTotal\n",
    "df['reviewsTotal'] = df['userReviewsTotal'] + df['criticReviewsTotal']\n",
    "\n",
    "#drop columns that are not needed\n",
    "columns_to_drop = [\n",
    "    'totalImages', 'totalVideos', 'quotesTotal', 'externalLinks',\n",
    "    'totalCredits', 'castNumber', 'writerCredits', 'directorsCredits',\n",
    "    'awardWins', 'awardNominationsExcludeWins',\n",
    "    'userReviewsTotal', 'criticReviewsTotal',\n",
    "    'bestRating', 'worstRating', 'isRatable'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>countryOfOrigin_freq_enc</th>\n",
       "      <th>countryOfOrigin_NA</th>\n",
       "      <th>countryOfOrigin_AF</th>\n",
       "      <th>countryOfOrigin_AS</th>\n",
       "      <th>countryOfOrigin_EU</th>\n",
       "      <th>countryOfOrigin_OC</th>\n",
       "      <th>countryOfOrigin_SA</th>\n",
       "      <th>countryOfOrigin_UNK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.399732</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.046115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.399732</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.399732</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.046115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149526</th>\n",
       "      <td>0.001417</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149527</th>\n",
       "      <td>0.017834</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149528</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149529</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149530</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149531 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        countryOfOrigin_freq_enc  countryOfOrigin_NA  countryOfOrigin_AF  \\\n",
       "0                       0.399732                   1                   0   \n",
       "1                       0.046115                   0                   0   \n",
       "2                       0.399732                   1                   0   \n",
       "3                       0.399732                   1                   0   \n",
       "4                       0.046115                   0                   0   \n",
       "...                          ...                 ...                 ...   \n",
       "149526                  0.001417                   0                   0   \n",
       "149527                  0.017834                   0                   0   \n",
       "149528                  0.000000                   0                   0   \n",
       "149529                  0.000000                   0                   0   \n",
       "149530                  0.000000                   0                   0   \n",
       "\n",
       "        countryOfOrigin_AS  countryOfOrigin_EU  countryOfOrigin_OC  \\\n",
       "0                        0                   0                   0   \n",
       "1                        0                   1                   0   \n",
       "2                        0                   0                   0   \n",
       "3                        0                   0                   0   \n",
       "4                        0                   1                   0   \n",
       "...                    ...                 ...                 ...   \n",
       "149526                   0                   0                   0   \n",
       "149527                   0                   1                   0   \n",
       "149528                   0                   0                   0   \n",
       "149529                   0                   0                   0   \n",
       "149530                   0                   0                   0   \n",
       "\n",
       "        countryOfOrigin_SA  countryOfOrigin_UNK  \n",
       "0                        0                    0  \n",
       "1                        0                    0  \n",
       "2                        0                    0  \n",
       "3                        0                    0  \n",
       "4                        0                    0  \n",
       "...                    ...                  ...  \n",
       "149526                   1                    0  \n",
       "149527                   0                    0  \n",
       "149528                   0                    0  \n",
       "149529                   0                    0  \n",
       "149530                   0                    0  \n",
       "\n",
       "[149531 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['countryOfOrigin_freq_enc', 'countryOfOrigin_NA', 'countryOfOrigin_AF',\n",
    "    'countryOfOrigin_AS', 'countryOfOrigin_EU', 'countryOfOrigin_OC', 'countryOfOrigin_SA', 'countryOfOrigin_UNK' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a stratified 70/30 split based on the 'titleType' column\n",
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.3,\n",
    "    stratify=df['titleType'],\n",
    "    random_state=42\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputation of runtimeMinutes missing values \n",
    "\n",
    "from typing import Callable\n",
    "def impute_runtime_minutes(df: pd.DataFrame, perc: float | None=0.99) -> Callable[[pd.DataFrame], pd.Series]:\n",
    "    \"\"\"\n",
    "    Impute missing values in the 'runtimeMinutes' column of the given DataFrame.\n",
    "    Assigns to missing values randomly sampled data out of the central perc% range.\n",
    "    Also imputes the values for rows outside the perc range if not None.\n",
    "    Imputation is done separately for each 'titleType' category.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to impute.\n",
    "        \n",
    "        perc (float | None): The central percentile range for imputing values. Default is 0.9.\n",
    "\n",
    "    Returns:\n",
    "        Callable[[pd.DataFrame], pd.Series]: A function that takes a DataFrame and returns the imputed 'runtimeMinutes' column.\n",
    "    \"\"\"\n",
    "    # If perc is not None, calculate the lower and upper bounds for the central perc% range\n",
    "    if perc is not None:\n",
    "        lower_bound = (1 - perc) / 2\n",
    "        upper_bound = 1 - lower_bound\n",
    "        perc_threshold = df.groupby('titleType')['runtimeMinutes'].quantile([lower_bound, upper_bound]).unstack()\n",
    "\n",
    "    # Define the percentiles for each titleType category, while cutting off outliers\n",
    "    percentiles = df.groupby('titleType')['runtimeMinutes'].quantile([0.3, 0.7]).unstack()\n",
    "\n",
    "    def impute_rt_mins(df: pd.DataFrame) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Impute missing values in the 'runtimeMinutes' column of the given DataFrame.\n",
    "        Assigns to missing values randomly sampled data out of the central perc% range.\n",
    "        Imputation is done separately for each 'titleType' category.\n",
    "        Parameters:\n",
    "            df (pd.DataFrame): The DataFrame to impute.\n",
    "        Returns:\n",
    "            pd.Series: The imputed 'runtimeMinutes' column.\n",
    "        \"\"\"\n",
    "        # Group the data by 'titleType'\n",
    "        groups = df.groupby('titleType')['runtimeMinutes']\n",
    "\n",
    "        # Create a copy of the original column to preserve order\n",
    "        imputed_runtime = df['runtimeMinutes'].copy()\n",
    "\n",
    "        # Iterate over each group and impute missing values\n",
    "        for title_type, group in groups:\n",
    "            lower = percentiles.loc[title_type, 0.3]\n",
    "            upper = percentiles.loc[title_type, 0.7]\n",
    "\n",
    "            # Get valid values within the 30-70 percentile range\n",
    "            valid_values = group[(group >= lower) & (group <= upper)].dropna()\n",
    "\n",
    "            # Filter the group to include only rows within the central perc% range\n",
    "            if perc is not None:\n",
    "                central_lower = perc_threshold.loc[title_type, lower_bound]\n",
    "                central_upper = perc_threshold.loc[title_type, upper_bound]\n",
    "                valid_values = valid_values[(valid_values >= central_lower) & (valid_values <= central_upper)]\n",
    "\n",
    "            for index in group.index:\n",
    "                # If the value is outside the central perc% range, assign a random sample from the valid values\n",
    "                if group[index] < lower or group[index] > upper:\n",
    "                    imputed_runtime.loc[index] = valid_values.sample(n=1, replace=True, random_state=42).values[0]\n",
    "\n",
    "            # Sample values for missing entries\n",
    "            missing_count = group.isna().sum()\n",
    "            if missing_count > 0:\n",
    "                sampled_values = valid_values.sample(n=missing_count, replace=True, random_state=42)\n",
    "                # Assign sampled values to the missing positions\n",
    "                imputed_runtime.loc[group.index[group.isna()]] = sampled_values.values\n",
    "\n",
    "        return imputed_runtime\n",
    "    \n",
    "    return impute_rt_mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Fit the imputer on training data\n",
    "runtime_imputer = impute_runtime_minutes(train_df)\n",
    "\n",
    "# Step 2: Apply to train\n",
    "train_df['runtimeMinutes'] = runtime_imputer(train_df)\n",
    "\n",
    "# Step 3: Apply to test\n",
    "test_df['runtimeMinutes'] = runtime_imputer(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set saved to: /Users/chiaraferrara/Desktop/Unipi/Magistrale/DM 2/dm2_project/dm2_dataset_2425_imdb/train70_clf.csv\n",
      "Test set saved to: /Users/chiaraferrara/Desktop/Unipi/Magistrale/DM 2/dm2_project/dm2_dataset_2425_imdb/test30_clf.csv\n"
     ]
    }
   ],
   "source": [
    "# # Determine the output directory (same as input file)\n",
    "# output_dir = os.path.dirname(file_path)\n",
    "\n",
    "# # Define output file paths\n",
    "# train_path = os.path.join(output_dir, 'train70_clf.csv')\n",
    "# test_path = os.path.join(output_dir, 'test30_clf.csv')\n",
    "\n",
    "# # Save the train and test splits as CSV files\n",
    "# train_df.to_csv(train_path, index=False)\n",
    "# test_df.to_csv(test_path, index=False)\n",
    "\n",
    "# # Confirm save paths\n",
    "# print(f\"Train set saved to: {train_path}\")\n",
    "# print(f\"Test set saved to: {test_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
